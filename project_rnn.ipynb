{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#!pip install pyhealth torch polars numpy\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# set seed\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "obj = pickle.load(open(os.path.join('data/', 'allevents_by_episode'), 'rb'))\n",
    "obj.estimated_size()/(1024**2)\n",
    "patients = obj.select(pl.col('subject_id')).to_series().to_list()\n",
    "seqs = obj.select(pl.col('uniq_itemid')).to_series().to_list()\n",
    "mortality = obj.select(pl.col('mortality_tf')).to_series().to_list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemset = list(set(list(set([each_j for i in seqs for each_i in i for each_j in each_i]))))\n",
    "code2idx = {itemset[i]: i for i in range(len(itemset))}\n",
    "idx2code = {i: itemset[i] for i in range(len(itemset))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer dataset\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, patients, seqs, mortality):\n",
    "        self.patients = patients\n",
    "        self.x = seqs\n",
    "        self.y = mortality\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, index):\n",
    "        return self.patients[index], self.x[index], self.y[index]\n",
    "dataset = CustomDataset(patients, seqs, mortality)\n",
    "assert len(dataset) == len(obj) #TODO write test separately "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "(10, 8, 313)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m loader \u001b[39m=\u001b[39m DataLoader(dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, collate_fn\u001b[39m=\u001b[39mcollate_fn)\n\u001b[1;32m     26\u001b[0m loader_iter \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(loader)\n\u001b[0;32m---> 27\u001b[0m x, masks, rev_x, rev_masks, y \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(loader_iter)\n\u001b[1;32m     28\u001b[0m \u001b[39massert\u001b[39;00m x\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m masks\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39m10\u001b[39m, \u001b[39m689\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[39massert\u001b[39;00m y\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39m10\u001b[39m,)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "Cell \u001b[0;32mIn[36], line 17\u001b[0m, in \u001b[0;36mcollate_fn\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m i_patient, patient \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(patients):\n\u001b[1;32m     16\u001b[0m     \u001b[39mfor\u001b[39;00m j_item, item \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(seqs):\n\u001b[0;32m---> 17\u001b[0m        padded_item \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mconcat([torch\u001b[39m.\u001b[39;49mtensor(item), torch\u001b[39m.\u001b[39mzeros(max_num_items \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(item))])\u001b[39m.\u001b[39mlong()\n\u001b[1;32m     18\u001b[0m        x[i_patient, :] \u001b[39m=\u001b[39m padded_item\n\u001b[1;32m     19\u001b[0m        masks[i_patient, :] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mwhere(padded_item \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39mTrue\u001b[39;00m, \u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "# Collate function\n",
    "def collate_fn(data):\n",
    "    patients, seqs, labels = zip(*data)\n",
    "    num_patients = len(patients)\n",
    "    max_num_events = max([len(event) for event in seqs])\n",
    "    max_num_itemids = max([len(itemid) for event in seqs for itemid in event])\n",
    "    tensor_shape = (num_patients, max_num_events, max_num_itemids)\n",
    "    x =        torch.zeros(tensor_shape, dtype=torch.long)\n",
    "    rev_x =    torch.zeros(tensor_shape, dtype=torch.long)\n",
    "    masks =    torch.zeros(tensor_shape, dtype=torch.bool)\n",
    "    rev_masks = torch.zeros(tensor_shape, dtype=torch.bool) \n",
    "    y =        torch.tensor(labels, dtype=torch.long)\n",
    "    for i_patient, patient in enumerate(patients):\n",
    "        for j_item, item in enumerate(seqs):\n",
    "           padded_item = torch.concat([torch.tensor(item), torch.zeros(max_num_items - len(item))]).long()\n",
    "           x[i_patient, :] = padded_item\n",
    "           masks[i_patient, :] = torch.where(padded_item != 0, True, False)\n",
    "           rev_x[i_patient, :] = torch.flip(padded_item.unsqueeze(-1), dims=(-1,0)).squeeze(-1)\n",
    "           rev_masks[i_patient, :] = torch.where(rev_x[i_patient, :] != 0, True, False)\n",
    "    return x, masks, rev_x, rev_masks, y\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "loader = DataLoader(dataset, batch_size=10, collate_fn=collate_fn)\n",
    "loader_iter = iter(loader)\n",
    "x, masks, rev_x, rev_masks, y = next(loader_iter)\n",
    "assert x.shape == masks.shape == (10, 689)\n",
    "assert y.shape == (10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CustomDataset at 0x7f1bb18fc650>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = int(len(dataset)*0.8), int(len(dataset)*0.1), len(dataset) - int(len(dataset)*0.8) -  int(len(dataset)*0.1)\n",
    "lengths = [train, val, test]\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset=dataset, lengths=lengths)\n",
    "\n",
    "def load_data(train_dataset, val_dataset, test_dataset, collate_fn):\n",
    "    batch_size = 32\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "train_loader, val_loader, test_loader = load_data(train_dataset, val_dataset, test_dataset, collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_embeddings_with_masks(x, masks):\n",
    "    \"\"\"\n",
    "    x    (batch_size, #item, embedding_dim)\n",
    "    mask (batch_size, #item)\n",
    "    return (batch_size, embedding_dim)\n",
    "    \"\"\"\n",
    "    mask = mask.unsqueeze(-1).expand(x.shape[0], x.shape[1], x.shape[2])\n",
    "    return torch.sum(mask * x, 1)\n",
    "def get_last_item(hidden_states, masks):\n",
    "    \"\"\"\n",
    "    hidden_states: (batch_size, #item, embedding_dim)\n",
    "    masks:         (batch_size, #item, embedding_dim)\n",
    "    return last_hidden_state: (batch_size, embedding_dim)\n",
    "    \"\"\"\n",
    "    #print(torch.sum(masks, 1))\n",
    "    idx_last_item = torch.argmin(torch.sum(masks, 2), 1)\n",
    "    print(idx_last_item)\n",
    "    return hidden_states[:, \n",
    "                         torch.where(idx_last_item - 1 < 0, max(idx_last_item), idx_last_item - 1),\n",
    "                         :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0148e+00, -5.4286e-01,  4.3074e-01, -1.9257e+00],\n",
       "         [ 1.2756e+00, -1.1316e+00,  8.6800e-01,  7.0788e-01],\n",
       "         [ 2.0585e-01, -9.3001e-01,  1.1425e-01, -4.4503e-01],\n",
       "         [-8.5306e-01, -8.4074e-01, -3.9633e-01, -2.5913e-01],\n",
       "         [-6.7731e-01,  7.0912e-02, -4.5838e-01,  1.6847e+00]],\n",
       "\n",
       "        [[ 1.4235e-01,  6.4272e-01, -7.0122e-01,  1.0413e+00],\n",
       "         [ 1.5445e+00,  1.1718e+00, -3.8031e-01,  1.7336e+00],\n",
       "         [-4.5109e-01, -8.9362e-01, -2.7579e-01,  7.6457e-01],\n",
       "         [-1.3222e+00, -2.5249e-01, -2.0878e+00, -5.7322e-01],\n",
       "         [-8.1685e-01, -4.7587e-01,  8.2872e-01, -1.6278e-01]],\n",
       "\n",
       "        [[-1.4798e+00,  4.8731e-01, -3.0128e+00,  4.4386e-01],\n",
       "         [ 3.5976e-01, -1.2348e-02,  2.1852e-01, -1.2815e+00],\n",
       "         [ 2.4112e+00,  1.9991e+00,  7.8479e-01, -1.0195e+00],\n",
       "         [-2.1058e-01,  6.2684e-01,  9.3176e-01,  1.8675e-01],\n",
       "         [ 9.5893e-01, -1.1371e+00,  1.3051e-03,  1.3174e+00]]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_num_items = 5\n",
    "batch_size = 3\n",
    "embedding_dims = 4\n",
    "torch.random.manual_seed(12345)\n",
    "hidden_states = torch.randn((batch_size, max_num_items, embedding_dims))\n",
    "#print(hidden_states)\n",
    "masks = torch.ones_like(hidden_states)\n",
    "masks[:,3:,:] = 0 \n",
    "masks[0,2:,:] = 0 \n",
    "masks[2,1:,:] = 0\n",
    "masks[0,:,2:] = 0\n",
    "masks[1,:,3:] = 0\n",
    "masks = masks.bool()\n",
    "#print(masks)\n",
    "out = get_last_item(hidden_states, masks)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False, False, False,  ...,  True, False, False],\n",
       "         [False, False,  True,  ..., False, False, False],\n",
       "         [ True, False,  True,  ..., False, False,  True],\n",
       "         ...,\n",
       "         [False,  True, False,  ...,  True,  True,  True],\n",
       "         [False,  True, False,  ..., False, False, False],\n",
       "         [False, False,  True,  ..., False,  True, False]],\n",
       "\n",
       "        [[False,  True, False,  ..., False, False, False],\n",
       "         [False, False, False,  ...,  True,  True,  True],\n",
       "         [False, False, False,  ...,  True, False, False],\n",
       "         ...,\n",
       "         [ True, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ...,  True, False,  True],\n",
       "         [ True,  True,  True,  ...,  True, False, False]],\n",
       "\n",
       "        [[False, False,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ...,  True, False, False],\n",
       "         [ True,  True,  True,  ...,  True, False, False],\n",
       "         ...,\n",
       "         [False,  True, False,  ..., False,  True,  True],\n",
       "         [ True, False, False,  ..., False, False,  True],\n",
       "         [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[False, False, False,  ..., False, False, False],\n",
       "         [False, False,  True,  ..., False, False, False],\n",
       "         [ True, False, False,  ..., False,  True, False],\n",
       "         ...,\n",
       "         [ True,  True, False,  ...,  True,  True,  True],\n",
       "         [ True,  True, False,  ..., False,  True, False],\n",
       "         [False, False,  True,  ...,  True, False,  True]],\n",
       "\n",
       "        [[ True, False, False,  ...,  True, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False,  True, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [ True,  True, False,  ...,  True, False,  True],\n",
       "         [ True, False,  True,  ..., False,  True, False],\n",
       "         [ True, False, False,  ...,  True,  True,  True]],\n",
       "\n",
       "        [[False, False,  True,  ..., False,  True,  True],\n",
       "         [False,  True,  True,  ...,  True, False,  True],\n",
       "         [ True,  True, False,  ..., False,  True, False],\n",
       "         ...,\n",
       "         [ True, False, False,  ..., False,  True, False],\n",
       "         [ True,  True, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
