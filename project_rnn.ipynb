{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyhealth\n",
      "  Using cached pyhealth-1.1.3-py2.py3-none-any.whl (113 kB)\n",
      "Collecting torch\n",
      "  Using cached torch-2.0.0-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
      "Requirement already satisfied: polars in /workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages (0.17.8)\n",
      "Requirement already satisfied: numpy in /workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages (1.24.3)\n",
      "Collecting rdkit>=2022.03.4 (from pyhealth)\n",
      "  Using cached rdkit-2022.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
      "Collecting scikit-learn>=0.24.2 (from pyhealth)\n",
      "  Using cached scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "Collecting networkx>=2.6.3 (from pyhealth)\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: pandas>=1.3.2 in /workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages (from pyhealth) (2.0.1)\n",
      "Collecting tqdm (from pyhealth)\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: filelock in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from torch) (3.10.3)\n",
      "Requirement already satisfied: typing-extensions in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from torch) (4.5.0)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "Requirement already satisfied: jinja2 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch)\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch)\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
      "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91 (from torch)\n",
      "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch)\n",
      "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch)\n",
      "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3 (from torch)\n",
      "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91 (from torch)\n",
      "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "Collecting triton==2.0.0 (from torch)\n",
      "  Using cached triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "Requirement already satisfied: setuptools in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (67.6.0)\n",
      "Requirement already satisfied: wheel in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.40.0)\n",
      "Collecting cmake (from triton==2.0.0->torch)\n",
      "  Using cached cmake-3.26.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
      "Collecting lit (from triton==2.0.0->torch)\n",
      "  Using cached lit-16.0.2-py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from pandas>=1.3.2->pyhealth) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages (from pandas>=1.3.2->pyhealth) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages (from pandas>=1.3.2->pyhealth) (2023.3)\n",
      "Collecting Pillow (from rdkit>=2022.03.4->pyhealth)\n",
      "  Using cached Pillow-9.5.0-cp311-cp311-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "Collecting scipy>=1.3.2 (from scikit-learn>=0.24.2->pyhealth)\n",
      "  Using cached scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.1 MB)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn>=0.24.2->pyhealth)\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn>=0.24.2->pyhealth)\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from jinja2->torch) (2.1.2)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.2->pyhealth) (1.16.0)\n",
      "Installing collected packages: mpmath, lit, cmake, tqdm, threadpoolctl, sympy, scipy, Pillow, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, networkx, joblib, scikit-learn, rdkit, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, pyhealth\n",
      "Successfully installed Pillow-9.5.0 cmake-3.26.3 joblib-1.2.0 lit-16.0.2 mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 pyhealth-1.1.3 rdkit-2022.9.5 scikit-learn-1.2.2 scipy-1.10.1 sympy-1.11.1 threadpoolctl-3.1.0 torch-2.0.0 tqdm-4.65.0 triton-2.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "!pip install pyhealth torch polars numpy\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# set seed\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "obj = pickle.load(open(os.path.join('data/', 'allevents_by_episode'), 'rb'))\n",
    "obj.estimated_size()/(1024**2)\n",
    "patients = list(range(len(obj)))\n",
    "seqs = obj.select(pl.col('uniq_itemid').cast(pl.List(pl.List(pl.Int32)))).to_series().to_list()\n",
    "mortality = obj.select(pl.col('mortality_tf')).to_series().to_list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemset = list(set(list(set([each_j for i in seqs for each_i in i for each_j in each_i]))))\n",
    "code2idx = {itemset[i]: i for i in range(len(itemset))}\n",
    "idx2code = {i: itemset[i] for i in range(len(itemset))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer dataset\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, patients, seqs, mortality):\n",
    "        self.patients = patients\n",
    "        self.seqs = seqs\n",
    "        self.labels = mortality\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, index):\n",
    "        return self.patients[index], self.seqs[index], self.labels[index]\n",
    "dataset = CustomDataset(patients, seqs, mortality)\n",
    "assert len(dataset) == len(obj) #TODO write test separately "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate function\n",
    "def collate_fn(data):\n",
    "    patients, seqs, labels = zip(*data)\n",
    "    num_patients = len(patients)\n",
    "    max_num_events = max([len(event) for event in seqs])\n",
    "    max_num_items = max([len(itemid) for event in seqs for itemid in event])\n",
    "    tensor_shape = (num_patients, max_num_events, max_num_items)\n",
    "    x =        torch.zeros(tensor_shape, dtype=torch.long)\n",
    "    rev_x =    torch.zeros(tensor_shape, dtype=torch.long)\n",
    "    masks =    torch.zeros(tensor_shape, dtype=torch.bool)\n",
    "    rev_masks = torch.zeros(tensor_shape, dtype=torch.bool) \n",
    "    y =        torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "\n",
    "    for i_patient, events in enumerate(seqs):\n",
    "        for i_event, item in enumerate(events):\n",
    "            padded_item = torch.concat([torch.tensor(item),\n",
    "                                        torch.zeros(max_num_items - len(item))]).long()\n",
    "            x[i_patient, i_event, :] = padded_item\n",
    "            masks[i_patient, i_event, :] = torch.where(padded_item!=0,1,0)  \n",
    "    for i_patient, events in enumerate(seqs):\n",
    "        idx_all_real_events = torch.sum(x[i_patient, :, :], dim=(1))!= 0\n",
    "        idx_padded_events =torch.sum(x[i_patient, :, :], dim=(1))== 0\n",
    "        fliped = torch.flip(x[i_patient, idx_all_real_events, :].unsqueeze(1), (0,)).squeeze(1)\n",
    "        rev_x[i_patient, :, :] = torch.concat((fliped, x[i_patient, idx_padded_events, :] ))\n",
    "        rev_masks[i_patient, :, :] = torch.where(rev_x[i_patient, :, :] != 0, True, False)\n",
    "    return x, masks, rev_x, rev_masks, y\n",
    "\n",
    "    \n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "loader = DataLoader(dataset, batch_size=10, collate_fn=collate_fn)\n",
    "loader_iter = iter(loader)\n",
    "x, masks, rev_x, rev_masks, y = next(loader_iter)\n",
    "assert x.shape == masks.shape == (10, 8, 313)\n",
    "assert y.shape == (10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = int(len(dataset)*0.8), int(len(dataset)*0.1), len(dataset) - int(len(dataset)*0.8) -  int(len(dataset)*0.1)\n",
    "lengths = [train, val, test]\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset=dataset, lengths=lengths)\n",
    "\n",
    "def load_data(train_dataset, val_dataset, test_dataset, collate_fn):\n",
    "    batch_size = 32\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "train_loader, val_loader, test_loader = load_data(train_dataset, val_dataset, test_dataset, collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_embeddings_with_masks(x, masks):\n",
    "    \"\"\"\n",
    "    x    (batch_size, #item, embedding_dim)\n",
    "    mask (batch_size, #item)\n",
    "    return (batch_size, embedding_dim)\n",
    "    \"\"\"\n",
    "    mask = mask.unsqueeze(-1).expand(x.shape[0], x.shape[1], x.shape[2])\n",
    "    return torch.sum(mask * x, 1)\n",
    "def get_last_item(hidden_states, masks):\n",
    "    \"\"\"\n",
    "    hidden_states: (batch_size, #item, embedding_dim)\n",
    "    masks:         (batch_size, #item, embedding_dim)\n",
    "    return last_hidden_state: (batch_size, embedding_dim)\n",
    "    \"\"\"\n",
    "    #print(torch.sum(masks, 1))\n",
    "    idx_last_item = torch.argmin(torch.sum(masks, 2), 1)\n",
    "    print(idx_last_item)\n",
    "    return hidden_states[:, \n",
    "                         torch.where(idx_last_item - 1 < 0, max(idx_last_item), idx_last_item - 1),\n",
    "                         :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0148e+00, -5.4286e-01,  4.3074e-01, -1.9257e+00],\n",
       "         [ 1.2756e+00, -1.1316e+00,  8.6800e-01,  7.0788e-01],\n",
       "         [ 2.0585e-01, -9.3001e-01,  1.1425e-01, -4.4503e-01],\n",
       "         [-8.5306e-01, -8.4074e-01, -3.9633e-01, -2.5913e-01],\n",
       "         [-6.7731e-01,  7.0912e-02, -4.5838e-01,  1.6847e+00]],\n",
       "\n",
       "        [[ 1.4235e-01,  6.4272e-01, -7.0122e-01,  1.0413e+00],\n",
       "         [ 1.5445e+00,  1.1718e+00, -3.8031e-01,  1.7336e+00],\n",
       "         [-4.5109e-01, -8.9362e-01, -2.7579e-01,  7.6457e-01],\n",
       "         [-1.3222e+00, -2.5249e-01, -2.0878e+00, -5.7322e-01],\n",
       "         [-8.1685e-01, -4.7587e-01,  8.2872e-01, -1.6278e-01]],\n",
       "\n",
       "        [[-1.4798e+00,  4.8731e-01, -3.0128e+00,  4.4386e-01],\n",
       "         [ 3.5976e-01, -1.2348e-02,  2.1852e-01, -1.2815e+00],\n",
       "         [ 2.4112e+00,  1.9991e+00,  7.8479e-01, -1.0195e+00],\n",
       "         [-2.1058e-01,  6.2684e-01,  9.3176e-01,  1.8675e-01],\n",
       "         [ 9.5893e-01, -1.1371e+00,  1.3051e-03,  1.3174e+00]]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_num_items = 5\n",
    "batch_size = 3\n",
    "embedding_dims = 4\n",
    "torch.random.manual_seed(12345)\n",
    "hidden_states = torch.randn((batch_size, max_num_items, embedding_dims))\n",
    "#print(hidden_states)\n",
    "masks = torch.ones_like(hidden_states)\n",
    "masks[:,3:,:] = 0 \n",
    "masks[0,2:,:] = 0 \n",
    "masks[2,1:,:] = 0\n",
    "masks[0,:,2:] = 0\n",
    "masks[1,:,3:] = 0\n",
    "masks = masks.bool()\n",
    "#print(masks)\n",
    "out = get_last_item(hidden_states, masks)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False, False, False,  ...,  True, False, False],\n",
       "         [False, False,  True,  ..., False, False, False],\n",
       "         [ True, False,  True,  ..., False, False,  True],\n",
       "         ...,\n",
       "         [False,  True, False,  ...,  True,  True,  True],\n",
       "         [False,  True, False,  ..., False, False, False],\n",
       "         [False, False,  True,  ..., False,  True, False]],\n",
       "\n",
       "        [[False,  True, False,  ..., False, False, False],\n",
       "         [False, False, False,  ...,  True,  True,  True],\n",
       "         [False, False, False,  ...,  True, False, False],\n",
       "         ...,\n",
       "         [ True, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ...,  True, False,  True],\n",
       "         [ True,  True,  True,  ...,  True, False, False]],\n",
       "\n",
       "        [[False, False,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ...,  True, False, False],\n",
       "         [ True,  True,  True,  ...,  True, False, False],\n",
       "         ...,\n",
       "         [False,  True, False,  ..., False,  True,  True],\n",
       "         [ True, False, False,  ..., False, False,  True],\n",
       "         [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[False, False, False,  ..., False, False, False],\n",
       "         [False, False,  True,  ..., False, False, False],\n",
       "         [ True, False, False,  ..., False,  True, False],\n",
       "         ...,\n",
       "         [ True,  True, False,  ...,  True,  True,  True],\n",
       "         [ True,  True, False,  ..., False,  True, False],\n",
       "         [False, False,  True,  ...,  True, False,  True]],\n",
       "\n",
       "        [[ True, False, False,  ...,  True, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False,  True, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [ True,  True, False,  ...,  True, False,  True],\n",
       "         [ True, False,  True,  ..., False,  True, False],\n",
       "         [ True, False, False,  ...,  True,  True,  True]],\n",
       "\n",
       "        [[False, False,  True,  ..., False,  True,  True],\n",
       "         [False,  True,  True,  ...,  True, False,  True],\n",
       "         [ True,  True, False,  ..., False,  True, False],\n",
       "         ...,\n",
       "         [ True, False, False,  ..., False,  True, False],\n",
       "         [ True,  True, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
